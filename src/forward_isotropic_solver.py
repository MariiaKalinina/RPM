# -*- coding: utf-8 -*-
"""FORWARD-ISOTROPIC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EJ-DocZ2hURa5ruz6PgmO8m_ZajQE9Cj
"""



import numpy as np
import pandas as pd
import sys
import os
from typing import Dict, List, Union, Tuple, Optional, Callable
from scipy import integrate
from numpy import linalg as LA
from math import pi
import logging
import re

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def validate_inputs(phi: Union[List[float], np.ndarray],
                   lambda_i: Union[List[float], np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:
    """Validate and normalize inputs with strict checks"""
    phi = np.asarray(phi, dtype=np.float64).flatten()
    lambda_i = np.asarray(lambda_i, dtype=np.float64).flatten()

    if np.any(lambda_i <= 0):
        raise ValueError("All thermal conductivities must be positive")

    if len(phi) != len(lambda_i):
        raise ValueError(f"Length mismatch: phi ({len(phi)}) vs lambda_i ({len(lambda_i)})")

    total_phi = np.sum(phi)
    if not np.isclose(total_phi, 1.0, atol=1e-6):
        phi = phi / total_phi
        print(f"Volume fractions not summing to 1 ({total_phi:.6f}), normalizing...")

    return phi, lambda_i

def Wiener_Upper_Bound(phi: List[float], lambda_i: List[float], alpha_i: Optional[List[float]] = None) -> float:
    """Wiener's upper bound (arithmetic mean)"""
    phi, lam = validate_inputs(phi, lambda_i)
    return np.sum(phi * lam)

def Wiener_Lower_Bound(phi: List[float], lambda_i: List[float], alpha_i: Optional[List[float]] = None) -> float:
    """Wiener's lower bound (harmonic mean)"""
    phi, lam = validate_inputs(phi, lambda_i)
    return 1.0 / np.sum(phi / (lam + 1e-10))

def Wiener_Average(phi: List[float], lambda_i: List[float], alpha_i: Optional[List[float]] = None) -> float:
    """Geometric mean of Wiener bounds"""
    upper = Wiener_Upper_Bound(phi, lambda_i)
    lower = Wiener_Lower_Bound(phi, lambda_i)
    return np.mean([upper, lower])

def Lichtenecker(phi: List[float], lambda_i: List[float], alpha_i: Optional[List[float]] = None) -> float:
    """Lichtenecker's logarithmic mixing rule"""
    phi, lam = validate_inputs(phi, lambda_i)
    return np.exp(np.sum(phi * np.log(lam + 1e-10)))

from typing import List, Optional
import numpy as np

def validate_inputs_HS(phi: List[float], lambda_i: List[float]) -> tuple[np.ndarray, np.ndarray]:
    """
    Validate and normalize inputs for volume fractions and thermal conductivities.

    Args:
        phi: List or array of volume fractions.
        lambda_i: List or array of thermal conductivities (W/m·K).

    Returns:
        Tuple of numpy arrays (phi, lambda_i) after validation.

    Raises:
        ValueError: If inputs are invalid (e.g., negative values, incorrect sum, or mismatched lengths).
    """
    phi = np.array(phi, dtype=float)
    lambda_i = np.array(lambda_i, dtype=float)

    if len(phi) != len(lambda_i):
        raise ValueError("Volume fractions and conductivities must have the same length")
    if len(phi) < 1:
        raise ValueError("At least one phase is required")
    if any(phi < 0):
        raise ValueError("Volume fractions must be non-negative")
    if any(lambda_i <= 0):
        raise ValueError("Thermal conductivities must be positive")
    if not np.isclose(np.sum(phi), 1.0, rtol=1e-6):
        raise ValueError("Volume fractions must sum to 1.0")

    return phi, lambda_i

def Lower_Hashin_Strikman(phi: List[float],
                          lambda_i: List[float],
                          alpha_i: Optional[List[float]] = None) -> float:
    """
    Lower Hashin-Shtrikman bound for effective thermal conductivity.
    Assumes spherical inclusions (depolarization factor f = 1/3).

    Args:
        phi: List or array of volume fractions.
        lambda_i: List or array of thermal conductivities (W/m·K).
        alpha_i: Optional list or array of shape factors (not used, included for compatibility).

    Returns:
        float: Lower bound effective thermal conductivity (W/m·K).

    Raises:
        ValueError: If inputs are invalid or calculations result in near-zero denominators.
    """
    phi, lam = validate_inputs_HS(phi, lambda_i)
    if len(lam) == 1:
        return float(lam[0])

    L0 = min(lam)
    f = 1.0 / 3.0

    HS_comp1, HS_comp2 = [], []
    for v, k in zip(phi, lam):
        term_3 = v * k / (L0 * (1 - f) + k * f + 1e-10)
        term_12 = v * k / (L0 * (1 + f) / 2 + k * (1 - f) / 2 + 1e-10)
        HS_comp1.append((term_3 + 2 * term_12) / 3)
        HS_comp2.append(v / (L0 * (1 - f) + k * f + 1e-10))

    sum_comp2 = np.sum(HS_comp2)
    if abs(sum_comp2) < 1e-12:
        raise ValueError("Near-zero denominator in Lower HS bound calculation")

    return float(np.sum(HS_comp1) / sum_comp2)

def Upper_Hashin_Strikman(phi: List[float],
                          lambda_i: List[float],
                          alpha_i: Optional[List[float]] = None) -> float:
    """
    Upper Hashin-Shtrikman bound for effective thermal conductivity.
    Assumes spherical inclusions (depolarization factor f = 1/3).

    Args:
        phi: List or array of volume fractions.
        lambda_i: List or array of thermal conductivities (W/m·K).
        alpha_i: Optional list or array of shape factors (not used, included for compatibility).

    Returns:
        float: Upper bound effective thermal conductivity (W/m·K).

    Raises:
        ValueError: If inputs are invalid or calculations result in near-zero denominators.
    """
    phi, lam = validate_inputs_HS(phi, lambda_i)
    if len(lam) == 1:
        return float(lam[0])

    L0 = max(lam)
    f = 1.0 / 3.0

    HS_comp1, HS_comp2 = [], []
    for v, k in zip(phi, lam):
        term_3 = v * k / (L0 * (1 - f) + k * f + 1e-10)
        term_12 = v * k / (L0 * (1 + f) / 2 + k * (1 - f) / 2 + 1e-10)
        HS_comp1.append((term_3 + 2 * term_12) / 3)
        HS_comp2.append(v / (L0 * (1 - f) + k * f + 1e-10))

    sum_comp2 = np.sum(HS_comp2)
    if abs(sum_comp2) < 1e-12:
        raise ValueError("Near-zero denominator in Upper HS bound calculation")

    return float(np.sum(HS_comp1) / sum_comp2)

def Hashin_Strikman_Average(phi: List[float],
                            lambda_i: List[float],
                            alpha_i: Optional[List[float]] = None) -> float:
    """
    Geometric mean of Hashin-Shtrikman bounds with fallback handling.

    Args:
        phi: List or array of volume fractions.
        lambda_i: List or array of thermal conductivities (W/m·K).
        alpha_i: Optional list or array of shape factors (not used, included for compatibility).

    Returns:
        float: Effective thermal conductivity average (W/m·K).

    Raises:
        Exception: If calculations fail, falls back to arithmetic mean.
    """
    try:
        phi, lam = validate_inputs_HS(phi, lambda_i)
        if len(lam) == 1:
            return float(lam[0])

        upper = Upper_Hashin_Strikman(phi, lam, alpha_i)
        lower = Lower_Hashin_Strikman(phi, lam, alpha_i)

        if np.isnan(upper) or np.isnan(lower):
            return float(np.sum(phi * lam))

        if upper <= 0 or lower <= 0:
            return float(np.sum(phi * lam))

        if np.isclose(upper, lower, rtol=1e-6):
            return float(upper)

        geometric_mean = np.mean([upper, lower])
        if np.isnan(geometric_mean):
            return float(np.mean([upper, lower]))

        return float(geometric_mean)

    except Exception as e:
        print(f"Hashin-Shtrikman average calculation failed: {e}. Falling back to arithmetic mean.")
        return float(np.sum(phi * lambda_i))

import numpy as np
from scipy.optimize import root_scalar

def validate_inputs_Bruggeman(volume_fractions, thermal_conductivities):
    """Validate and prepare inputs for Bruggeman calculation with enhanced checks"""
    phi = np.asarray(volume_fractions, dtype=float)
    lam = np.asarray(thermal_conductivities, dtype=float)

    if np.any(phi < 0):
        raise ValueError("Volume fractions must be ≥ 0")
    if np.any(lam <= 0):
        raise ValueError("Thermal conductivities must be > 0")

    mask = phi > 1e-10
    phi = phi[mask]
    lam = lam[mask]

    phi_sum = np.sum(phi)
    if phi_sum < 1e-10:
        raise ValueError("Sum of volume fractions is effectively zero")
    phi = phi / phi_sum

    return phi, lam

def Bruggeman_EMA(phi, lambda_i, alpha_i=None, tol=1e-8, max_iter=100):
    """
    Calculate effective thermal conductivity using Bruggeman's EMA.

    Parameters:
        phi (array-like): Volume fractions (must sum to 1 ± 1e-6)
        lambda_i (array-like): Component thermal conductivities (must be > 0)
        alpha_i (array-like, optional): Aspect ratios (unused in Bruggeman)
        tol (float): Convergence tolerance
        max_iter (int): Maximum iterations

    Returns:
        float: Effective thermal conductivity
    """
    volume_fractions = phi
    thermal_conductivities = lambda_i

    phi, lam = validate_inputs_Bruggeman(volume_fractions, thermal_conductivities)

    if len(phi) == 1:
        return float(lam[0])

    if len(phi) == 2:
        phi1, phi2 = phi
        lambda1, lambda2 = lam
        if phi2 < 1e-10:
            return float(lambda1)
        if phi1 < 1e-10:
            return float(lambda2)

        B = (3*phi2 - 1)*lambda2 + (3*phi1 - 1)*lambda1
        discriminant = B**2 + 8*lambda1*lambda2
        if discriminant >= 0:
            return float((B + np.sqrt(discriminant))) / 4

    def bruggeman_eq(leff):
        with np.errstate(divide='ignore', invalid='ignore'):
            terms = phi * (lam - leff) / (lam + 2*leff)
        terms = np.nan_to_num(terms, nan=0.0, posinf=0.0, neginf=0.0)
        return np.sum(terms)

    lower = max(1e-10, 0.1 * min(lam))
    upper = min(1e10, 10.0 * max(lam))

    methods = ['brentq', 'bisect', 'ridder']
    for method in methods:
        try:
            sol = root_scalar(bruggeman_eq, bracket=[lower, upper],
                             method=method, xtol=tol, maxiter=max_iter)
            if sol.converged:
                return float(sol.root)
        except (ValueError, RuntimeError):
            continue

    return float(np.exp(np.sum(phi * np.log(lam))))



def validate_inputs_Maxwell_Garnett(phi, lambda_i):
    """
    Validate inputs for Maxwell-Garnett model.
    Ensures volume fractions sum to 1 and converts inputs to NumPy arrays.
    """
    phi = np.array(phi, dtype=float)
    lambda_i = np.array(lambda_i, dtype=float)

    if len(phi) != len(lambda_i):
        raise ValueError("Volume fractions and thermal conductivities must have the same length.")
    if not np.isclose(np.sum(phi), 1.0, rtol=1e-5):
        raise ValueError("Volume fractions must sum to 1.")
    if np.any(phi < 0) or np.any(lambda_i <= 0):
        raise ValueError("Volume fractions and thermal conductivities must be non-negative.")

    return phi, lambda_i

def Maxwell_Garnett_NComponent(volume_fractions, thermal_conductivities, matrix_index=0,
                              depolarization_factors=None):
    """
    Generalized Maxwell-Garnett effective medium theory for N-component composites.
    Handles ellipsoidal inclusions via depolarization factors.
    Returns scalar (isotropic) or tuple (anisotropic).
    """
    phi = np.array(volume_fractions)
    lam = np.array(thermal_conductivities)
    lam0 = lam[matrix_index]

    if depolarization_factors is None:
        L = np.array([(1/3, 1/3, 1/3)] * (len(phi)-1))
    elif isinstance(depolarization_factors, tuple):
        L = np.array([depolarization_factors] * (len(phi)-1))
    else:
        L = np.array(depolarization_factors)

    phi_incl = np.delete(phi, matrix_index)
    lam_incl = np.delete(lam, matrix_index)

    lambda_eff = []
    for axis in range(3):
        L_axis = L[:, axis]
        beta = (lam_incl - lam0) / (lam_incl + L_axis * lam0 + 1e-10)
        sum_phi_beta = np.sum(phi_incl * beta)
        lambda_axis = lam0 * (1 + sum_phi_beta / (1 - sum_phi_beta + 1e-10))
        lambda_eff.append(lambda_axis)

    if np.allclose(L[:,0], L[:,1]) and np.allclose(L[:,0], L[:,2]):
        return lambda_eff[0]
    else:
        return tuple(lambda_eff)


def Maxwell(phi, lambda_i, alpha_i=None):
    """
    N-component Maxwell-Garnett model with enforced spherical inclusions (AR = 1).
    Ignores input ARs and uses depolarization factor L = 1/3 per axis.
    Matrix is assumed to be index 0.
    """

    phi, lambda_i = validate_inputs_Maxwell_Garnett(phi, lambda_i)
    depolarization_factors = None

    result = Maxwell_Garnett_NComponent(
        volume_fractions=phi,
        thermal_conductivities=lambda_i,
        matrix_index=0,
        depolarization_factors=depolarization_factors
    )

    return float(result) if isinstance(result, (float, int)) else float(np.mean(result))


class GSAModel:
    """
    Generalized Self-Consistent Approach (GSA) model for calculating effective thermal conductivity
    of composite materials with ellipsoidal inclusions (both isotropic and anisotropic).
    """

    def __init__(self,
                 phi: Union[List[float], np.ndarray],
                 lambda_i: Union[List[float], List[np.ndarray]],
                 alpha_shape: Union[List[float], List[List[float]]],
                 max_iter: int = 1000,
                 tol: float = 1e-6,
                 method: str = 'self-consistent',
                 f_param: Optional[Union[List[float], np.ndarray]] = None,
                 isotropic: bool = True):

        self.phi = np.asarray(phi)
        self.lambda_i = [np.asarray(lam) if isinstance(lam, (list, np.ndarray)) else lam
                        for lam in lambda_i]
        self.alpha_shape = [np.asarray(alpha) if isinstance(alpha, (list, np.ndarray)) else alpha
                           for alpha in alpha_shape]
        self.max_iter = max_iter
        self.tol = tol
        self.method = method.lower()
        self.f_param = np.asarray(f_param) if f_param is not None else None
        self.isotropic = isotropic

        self._validate_inputs()
        self._process_inputs()

    def _validate_inputs(self) -> None:
        """Validate input parameters."""
        if not np.isclose(np.sum(self.phi), 1.0, atol=1e-4):
            raise ValueError("Volume fractions must sum to 1")

        if len(self.phi) != len(self.lambda_i) or len(self.phi) != len(self.alpha_shape):
            raise ValueError("phi, lambda_i, and alpha_shape must have same length")

        if any(self.phi < 0) or any(self.phi > 1):
            raise ValueError("Volume fractions must be between 0 and 1")

        if self.method not in ['self-consistent', 'f-model']:
            raise ValueError("Method must be 'self-consistent' or 'f-model'")

        if self.method == 'f-model' and self.f_param is None:
            raise ValueError("f_param must be provided for 'f-model' method")

    def _process_inputs(self) -> None:
        """Convert inputs to consistent tensor/scalar formats."""
        if self.isotropic:
            self.lambda_i = [np.eye(3)*lam if np.isscalar(lam) else lam
                            for lam in self.lambda_i]
        else:
            for i, lam in enumerate(self.lambda_i):
                if np.isscalar(lam):
                    raise ValueError("Anisotropic mode requires tensor inputs")

        if self.isotropic:
            self.alpha_shape = [alpha if np.isscalar(alpha) else alpha[0]
                              for alpha in self.alpha_shape]
        else:
            for i, alpha in enumerate(self.alpha_shape):
                if np.isscalar(alpha):
                    self.alpha_shape[i] = [alpha, alpha, alpha]

    @staticmethod
    def depolarization_factor(alpha: float) -> float:
        """Isotropic depolarization factor (scalar)."""
        if alpha < 1:
            t1 = alpha ** 2
            t2 = 1 / t1
            t4 = np.sqrt(t2 - 1)
            t5 = np.arctan(t4)
            return t2 * (t4 - t5) / (t4 ** 3)
        elif alpha > 1:
            t1 = alpha ** 2
            t2 = 1 / t1
            t4 = np.sqrt(1 - t2)
            t6 = np.log((1 + t4) / (1 - t4))
            return t2 * (0.5 * t6 - t4) / (t4 ** 3)
        else:
            return 1 / 3

    def _calculate_g_isotropic(self, alpha: float, lambda_c: float) -> float:
        """Isotropic G factor calculation."""
        F = self.depolarization_factor(alpha)
        return F / lambda_c

    @staticmethod
    def calculate_g_tensor(alpha: List[float], X_c: np.ndarray) -> np.ndarray:
        """Anisotropic G-tensor calculation."""
        a1, a2, a3 = alpha
        g_components = np.zeros((3, 3))

        def integrand(theta, phi):
            n = np.array([
                np.sin(theta)*np.cos(phi)/a1,
                np.sin(theta)*np.sin(phi)/a2,
                np.cos(theta)/a3
            ])
            Lambda = np.sum(n[:, None] * X_c * n[None, :])
            Lambda = 1/Lambda * np.sin(theta)
            return (-1/(4*pi)) * np.outer(n, n) * Lambda

        for x in range(3):
            for y in range(3):
                result, _ = integrate.nquad(
                    lambda theta, phi: integrand(theta, phi)[x, y],
                    [[0, pi], [0, 2*pi]]
                )
                g_components[x, y] = result
        return g_components

    def _iso_sc_iteration(self, lambda_eff: float) -> float:
        """Corrected isotropic GSA iteration with proper directional averaging."""
        numerator = 0.0
        denominator = 0.0

        for phi_i, lam, alpha in zip(self.phi, self.lambda_i, self.alpha_shape):
            lambda_i = np.mean(np.diag(lam))
            F = self.depolarization_factor(alpha)

            D_long = lambda_eff * (1 - F) + lambda_i * F

            D_trans = lambda_eff * (1 + F) / 2 + lambda_i * (1 - F) / 2

            inv_D_avg_num = (lambda_i / D_long + 2 * lambda_i / D_trans) / 3
            inv_D_avg_den = (1 / D_long + 2 * 1 / D_trans) / 3

            numerator += phi_i * inv_D_avg_num
            denominator += phi_i * inv_D_avg_den

        return numerator / denominator

    def _iso_fmodel_calculation(self, lambda_c: float) -> float:
        """Isotropic F-model direct calculation."""
        numerator, denominator = 0.0, 0.0
        for phi_i, lam, alpha in zip(self.phi, self.lambda_i, self.alpha_shape):
            lambda_i = np.mean(np.diag(lam))
            G = self._calculate_g_isotropic(alpha, lambda_c)
            M_inv = 1 / (1 - G * (lambda_i - lambda_c))
            A = M_inv * lambda_i
            numerator += phi_i * A
            denominator += phi_i * M_inv
        return numerator / denominator

    def _isotropic_calculation(self) -> Tuple[float, int]:
        """Corrected isotropic GSA calculation with proper iteration."""
        if self.method != 'self-consistent':
            lambda_c = np.sum([f * np.mean(np.diag(lam)) for f, lam in zip(self.f_param, self.lambda_i)])
            return self._iso_fmodel_calculation(lambda_c), 1


        lambda_eff = np.average([np.mean(np.diag(lam)) for lam in self.lambda_i], weights=self.phi)

        for iteration in range(self.max_iter):
            try:
                new_lambda_eff = self._iso_sc_iteration(lambda_eff)
            except (OverflowError, ZeroDivisionError):
                raise RuntimeError("Numerical instability in GSA iteration (division by zero or overflow)")

            if abs(new_lambda_eff - lambda_eff) < self.tol:
                return new_lambda_eff, iteration + 1

            lambda_eff = new_lambda_eff

        raise RuntimeError(f"GSA did not converge within {self.max_iter} iterations")

    def _anisotropic_calculation(self) -> Tuple[np.ndarray, int]:
        """Full anisotropic tensor calculation."""
        if self.method == 'self-consistent':
            X_prev = self.lambda_i[0]
        else:  # F-model
            X_prev = sum(f*lam for f, lam in zip(self.f_param, self.lambda_i))

        for iteration in range(self.max_iter):
            G_tensors = [self.calculate_g_tensor(alpha, X_prev)
                        for alpha in self.alpha_shape]
            M_inv = [LA.inv(np.eye(3) - G @ (lam - X_prev))
                    for G, lam in zip(G_tensors, self.lambda_i)]
            A = [M_i @ lam for M_i, lam in zip(M_inv, self.lambda_i)]
            TC_c = sum(c*A_i for c, A_i in zip(self.phi, A))
            TC_z = LA.inv(sum(c*M_i for c, M_i in zip(self.phi, M_inv)))
            X_new = TC_c @ TC_z

            if self.method == 'f-model' or np.allclose(X_new, X_prev, atol=self.tol):
                return (np.mean(np.diag(X_new)) if self.isotropic else X_new, iteration+1)
            X_prev = X_new

        raise RuntimeError(f"No convergence in {self.max_iter} iterations")

    def calculate_effective_tc(self) -> Tuple[Union[float, np.ndarray], int]:
        """Main calculation interface."""
        if self.isotropic:
            return self._isotropic_calculation()
        return self._anisotropic_calculation()

    def calculate_effective_tc_bounds(self) -> Tuple[float, float]:
        """Wiener bounds (always returns isotropic values)."""
        if self.isotropic:
            lambdas = [np.mean(np.diag(lam)) if isinstance(lam, np.ndarray) else lam
                      for lam in self.lambda_i]
        else:
            lambdas = [np.mean(np.diag(lam)) for lam in self.lambda_i]
        return (1/np.sum(self.phi/lambdas), np.sum(self.phi*lambdas))


def GSA(phi: List[float], lambda_i: List[float], alpha_i: List[float]) -> float:
    """
    Corrected wrapper function for the GSA model.

    Args:
        phi: List of volume fractions (must sum to 1)
        lambda_i: List of thermal conductivities
        alpha_i: List of aspect ratios

    Returns:
        Effective thermal conductivity (float)
    """
    phi = np.asarray(phi)
    lambda_i = np.asarray(lambda_i)
    alpha_i = np.asarray(alpha_i)

    model = GSAModel(
        phi=phi,
        lambda_i=lambda_i,
        alpha_shape=alpha_i,
        method='self-consistent',
        isotropic=True
    )

    tc_value, _ = model.calculate_effective_tc()
    return float(tc_value)

class RockPropertiesProcessor:
    def __init__(self, input_file: str):
        self.df, self.phase_volumes, self.phase_aspect_ratios, self.range_parameters, self.model_config, self.phase_to_mix = self._load_input_file(input_file)

    def _parse_range(self, range_str: str, param_name: str = None) -> List[float]:
        range_str = range_str.strip()
        if range_str.startswith('R:'):
            parts = [p.strip() for p in range_str[2:].split(',')]
            if len(parts) != 3:
                raise ValueError("Range specification must have exactly 3 parameters (start,end,steps)")
            try:
                start = float(parts[0])
                end = float(parts[1])
                steps = int(float(parts[2]))
            except ValueError as e:
                raise ValueError(f"Invalid numeric value in range specification: {e}")
            if param_name in ["Volume", "Thermal_Conductivity", "Phases_Volume"]:
                return np.linspace(start, end, steps).tolist()
            if any('e' in p.lower() for p in parts[:2]) or (abs(start) < 1e-6 or abs(end) < 1e-6):
                if start <= 0 or end <= 0:
                    raise ValueError("Logarithmic range requires positive values")
                return np.logspace(np.log10(start), np.log10(end), steps).tolist()
            return np.linspace(start, end, steps).tolist()
        else:
            values = []
            for val in range_str.split(','):
                try:
                    values.append(float(val.strip()))
                except ValueError as e:
                    raise ValueError(f"Invalid numeric value in list: {val} - {e}")
            return values

    def _load_input_file(self, file_path: str) -> Tuple[pd.DataFrame, Dict, Dict, Dict, Dict, Dict]:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = []
                for line in f:
                    stripped = line.strip()
                    if not stripped or stripped.startswith('#'):
                        continue
                    lines.append(stripped)

            rock_type_line = None
            problem_line = None
            phase_volumes_line = None
            phase_aspect_ratios_line = None
            final_model = "GSA"

            for line in lines:
                if line.startswith("Rock Type:"):
                    rock_type_line = line[len("Rock Type:"):].strip()
                elif line.startswith("Problem:"):
                    problem_line = line[len("Problem:"):].strip()
                elif line.startswith("Phases_Volume:"):
                    phase_volumes_line = line[len("Phases_Volume:"):].strip()
                elif line.startswith("Phases_Aspect_Ratio:"):
                    phase_aspect_ratios_line = line[len("Phases_Aspect_Ratio:"):].strip()

            if rock_type_line:
                rock_types = [rt.strip().lower() for rt in rock_type_line.split(',')]
                if "organic rich mudstone" in rock_types:
                    print("Option 'Organic Rich Mudstone' is still in development.")
                    sys.exit(0)
                allowed_rock_types = {"carbonates", "sandstones"}
                if not set(rock_types).issubset(allowed_rock_types):
                    print(f"Warning: Unrecognized rock types {set(rock_types) - allowed_rock_types}, but continuing.")

            if problem_line:
                problem_parts = [p.strip() for p in problem_line.split('|')]
                if problem_parts[0].lower() == "inverse":
                    if len(problem_parts) == 1 or problem_parts[1] == '':
                        print("Option 'Problem: Inverse' is still in development.")
                        sys.exit(0)
                    else:
                        try:
                            rel_error = float(problem_parts[1])
                        except ValueError:
                            print("Invalid relative error value for Problem: Inverse")
                            sys.exit(1)

            header_found = False
            data_lines = []
            range_dict = {}
            model_config = {'final': final_model, 'phases': {}}

            for line in lines:
                if line.startswith("Rock Type:") or line.startswith("Problem:") or line.startswith("Phases_Volume:") or line.startswith("Phases_Aspect_Ratio:"):
                    continue
                if line.startswith('*'):
                    try:
                        param_part, range_part = [p.strip() for p in line[1:].split('|', 1)]
                        param_info = [x.strip() for x in param_part.split(',')]
                        if len(param_info) == 2 and param_info[0] in ['Phases_Aspect_Ratio', 'Phases_Volume']:
                            param_name, phase = param_info
                            values = self._parse_range(range_part, param_name)
                            range_dict[(param_name, phase)] = values
                        elif len(param_info) == 3:
                            param_name, phase, component = param_info
                            values = self._parse_range(range_part, param_name)
                            range_dict[(param_name, phase, component)] = values
                        else:
                            raise ValueError(f"Invalid range parameter format: {param_part}")
                    except Exception as e:
                        raise ValueError(f"Invalid range parameter format in line: {line}\nError: {e}")
                elif not header_found:
                    header = line.split()
                    if 'Hierarchy' in header:
                        expected_header = [
                            'Phase', 'Component', 'Thermal_Conductivity',
                            'Aspect_Ratio', 'Volume', 'Hierarchy', 'Model_Type'
                        ]
                    else:
                        expected_header = [
                            'Phase', 'Component', 'Thermal_Conductivity',
                            'Aspect_Ratio', 'Volume', 'Level', 'Model_Type'
                        ]
                    if len(header) != len(expected_header):
                        raise ValueError(
                            f"Header has {len(header)} columns, expected {len(expected_header)}\n"
                            f"Header: {header}\nExpected: {expected_header}"
                        )
                    header_found = True
                else:
                    data_lines.append(line)

            if not header_found:
                raise ValueError("No valid header line found in input file")

            data = []
            for line in data_lines:
                parts = line.split()
                if len(parts) != len(expected_header):
                    raise ValueError(f"Data line has incorrect number of columns: {line}")
                data.append(parts)

            df = pd.DataFrame(data, columns=expected_header)
            if 'Hierarchy' in df.columns:
                df = df.rename(columns={'Hierarchy': 'Level'})

            for col in ['Thermal_Conductivity', 'Aspect_Ratio', 'Volume', 'Level']:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            mix_phases = df[df['Phase'].str.startswith('Mix')]
            if not mix_phases.empty:
                final_model = mix_phases['Model_Type'].iloc[-1]
            else:
                final_model = "GSA"

            model_config['final'] = final_model

            for phase in df[~df['Phase'].str.startswith('Mix')]['Phase'].unique():
                phase_df = df[df['Phase'] == phase]
                if not phase_df['Volume'].isna().all():
                    volume_sum = phase_df['Volume'].sum()
                    if not np.isclose(volume_sum, 1.0, atol=0.001):
                        raise ValueError(f"Volumes for phase '{phase}' sum to {volume_sum:.6f}, but must sum to 1.0.")

            mix_phases = df[df['Phase'].str.startswith('Mix')]['Phase'].unique()
            for mix_phase in mix_phases:
                mix_df = df[df['Phase'] == mix_phase]
                if not mix_df['Volume'].isna().all():
                    volume_sum = mix_df['Volume'].sum()
                    if not np.isclose(volume_sum, 1.0, atol=0.001):
                        raise ValueError(f"Mix phase '{mix_phase}' volumes sum to {volume_sum:.6f}, but must sum to 1.0.")

            mix_df = df[df['Phase'].str.startswith('Mix')].copy()
            non_mix_df = df[~df['Phase'].str.startswith('Mix')]

            phase_volumes = {}
            phase_aspect_ratios = {}

            for _, row in mix_df.iterrows():
                component = row['Component']
                volume = row['Volume']
                aspect_ratio = row['Aspect_Ratio']

                if not pd.isna(volume):
                    phase_volumes[component] = volume
                if not pd.isna(aspect_ratio):
                    phase_aspect_ratios[component] = aspect_ratio

            for phase in non_mix_df['Phase'].unique():
                phase_df = non_mix_df[non_mix_df['Phase'] == phase]
                model_types = phase_df['Model_Type'].unique()

                if '-' in model_types:
                    model_type = '-'
                elif len(model_types) == 1:
                    model_type = model_types[0]
                else:
                    model_type = final_model

                model_config['phases'][phase] = {
                    'components': phase_df['Component'].tolist(),
                    'model_type': model_type,
                    'levels': phase_df['Level'].unique().tolist()
                }

            phase_to_mix = {}
            for phase in non_mix_df['Phase'].unique():
                mix_comps = []
                for comp in mix_df['Component']:
                    if comp == phase or comp.startswith(phase + '_'):
                        mix_comps.append(comp)
                if mix_comps:
                    phase_to_mix[phase] = mix_comps

            return df, phase_volumes, phase_aspect_ratios, range_dict, model_config, phase_to_mix

        except Exception as e:
            raise ValueError(f"Error processing input file '{file_path}': {str(e)}")

    def _normalize_volumes(self, df: pd.DataFrame, phase: str = None) -> pd.DataFrame:
        df = df.copy()
        if 'Normalized_phi' not in df.columns:
            df['Normalized_phi'] = np.nan

        if phase:
            phase_df = df[df['Phase'] == phase]
            phase_df_valid = phase_df[~phase_df['Volume'].isna()]

            if len(phase_df_valid) == 0:
                mix_components = self.phase_to_mix.get(phase, [])
                if mix_components:
                    mix_volumes = [self.phase_volumes.get(comp, 0) for comp in mix_components]
                    total_volume = sum(mix_volumes)
                    if total_volume <= 0:
                        raise ValueError(f"Total volume for phase {phase} is zero or negative")
                    for i, comp in enumerate(mix_components):
                        comp_name = comp.split('_')[-1] if '_' in comp else comp
                        comp_mask = (df['Phase'] == phase) & (df['Component'] == comp_name)
                        if comp_mask.any():
                            df.loc[comp_mask, 'Normalized_phi'] = mix_volumes[i] / total_volume
                else:
                    raise ValueError(f"No valid volumes found for phase {phase}")
            else:
                total_volume = phase_df_valid['Volume'].sum()
                if total_volume <= 0:
                    raise ValueError(f"Total volume for phase {phase} is zero or negative")
                df.loc[df['Phase'] == phase, 'Normalized_phi'] = df.loc[df['Phase'] == phase, 'Volume'] / total_volume
        else:
            df_valid = df[~df['Volume'].isna()]
            total_volume = df_valid['Volume'].sum()
            if total_volume <= 0:
                raise ValueError("Total volume is zero or negative")
            df['Normalized_phi'] = df['Volume'] / total_volume

        return df

    def _normalize_phase_volumes(self, phase_volumes: Dict[str, float], target_phase: str, target_volume: float) -> Dict[str, float]:
        new_volumes = phase_volumes.copy()
        total_other_volume = sum(v for k, v in phase_volumes.items() if k != target_phase)
        if total_other_volume <= 0:
            raise ValueError(f"Total volume for phases excluding {target_phase} is zero or negative")
        scaling_factor = (1.0 - target_volume) / total_other_volume
        new_volumes[target_phase] = target_volume
        for phase in new_volumes:
            if phase != target_phase:
                new_volumes[phase] *= scaling_factor
        return new_volumes

def get_model_function(model_name: str) -> Callable:
    if not isinstance(model_name, str):
        raise ValueError(f"Model name must be a string, got {type(model_name)}")
    model_name = model_name.strip()

    if model_name == '0':
        return GSA
    MODEL_MAP = {
        'LIH': Lichtenecker,
        'WIU': Wiener_Upper_Bound,
        'WIL': Wiener_Lower_Bound,
        'WIA': Wiener_Average,
        'HSU': Upper_Hashin_Strikman,
        'HSL': Lower_Hashin_Strikman,
        'HSA': Hashin_Strikman_Average,
        'GSA': GSA,
        'MAX': Maxwell,
        'BRG': Bruggeman_EMA
    }

    if model_name not in MODEL_MAP:
        raise ValueError(f"Unknown model: {model_name}. Available: {list(MODEL_MAP.keys())}")
    return MODEL_MAP[model_name]

def resolve_component(component_name, phase_results, non_mix_df, phase_volumes, phase_aspect_ratios, mix_row=None):

    if mix_row is not None and not pd.isna(mix_row['Thermal_Conductivity']):
        tc = mix_row['Thermal_Conductivity']
        if not pd.isna(mix_row['Aspect_Ratio']):
            ar = mix_row['Aspect_Ratio']
        else:
            _, ar = resolve_component(component_name, phase_results, non_mix_df, phase_volumes, phase_aspect_ratios, None)
        return tc, ar

    if component_name in phase_results:
        return phase_results[component_name]['tc'], phase_results[component_name]['ar']

    comp_rows = non_mix_df[non_mix_df['Component'] == component_name]
    if len(comp_rows) > 0:
        tc = comp_rows['Thermal_Conductivity'].values[0]
        ar = comp_rows['Aspect_Ratio'].values[0] if not pd.isna(comp_rows['Aspect_Ratio'].values[0]) else 1.0
        return tc, ar

    for phase_name in non_mix_df['Phase'].unique():
        if component_name.startswith(phase_name + '_'):
            if phase_name in phase_results:
                return phase_results[phase_name]['tc'], phase_results[phase_name]['ar']

    if component_name in phase_aspect_ratios:
        ar = phase_aspect_ratios[component_name]
    else:
        ar = 1.0

    return 1.0, ar

def determine_mix_hierarchy(mix_df):
    return sorted(mix_df['Phase'].unique())

def calculate_effective_tc(df: pd.DataFrame, phase_volumes: Dict[str, float], phase_aspect_ratios: Dict[str, float], model_config: Dict) -> Dict[str, float]:
    logger.info("Starting effective thermal conductivity calculation")

    non_mix_df = df[~df['Phase'].str.startswith('Mix')]
    mix_df = df[df['Phase'].str.startswith('Mix')]

    phase_results = {}
    for phase in non_mix_df['Phase'].unique():
        phase_df = non_mix_df[non_mix_df['Phase'] == phase]
        phase_model_type = model_config['phases'].get(phase, {}).get('model_type', 'GSA')

        if phase_model_type == '-':
            continue

        model_func = get_model_function(phase_model_type)

        has_individual_volumes = not phase_df['Volume'].isna().all()
        if has_individual_volumes:
            processor = RockPropertiesProcessor.__new__(RockPropertiesProcessor)
            processor.phase_to_mix = {}
            phase_df_normalized = processor._normalize_volumes(phase_df, phase)

            phi = phase_df_normalized['Normalized_phi'].values
            lambda_i = phase_df_normalized['Thermal_Conductivity'].values
            alpha_i = phase_df_normalized['Aspect_Ratio'].values
            alpha_i = np.where(np.isnan(alpha_i), 1.0, alpha_i)

            if not np.isclose(np.sum(phi), 1.0, atol=0.001):
                phi = phi / np.sum(phi)
        else:
            mix_components = []
            if hasattr(processor, 'phase_to_mix'):
                mix_components = processor.phase_to_mix.get(phase, [])

            if not mix_components:
                raise ValueError(f"No mix components found for phase {phase}")

            mix_volumes = [phase_volumes.get(comp, 0) for comp in mix_components]
            total_volume = sum(mix_volumes)

            if total_volume <= 0:
                raise ValueError(f"Total volume for phase {phase} is zero or negative")

            normalized_volumes = []
            lambda_values = []
            alpha_values = []

            for comp in mix_components:
                comp_name = comp.split('_')[-1] if '_' in comp else comp
                comp_rows = phase_df[phase_df['Component'] == comp_name]
                if len(comp_rows) > 0:
                    normalized_volumes.append(phase_volumes.get(comp, 0) / total_volume)
                    lambda_values.append(comp_rows['Thermal_Conductivity'].values[0])
                    aspect_ratio = phase_aspect_ratios.get(comp, comp_rows['Aspect_Ratio'].values[0])
                    if pd.isna(aspect_ratio):
                        aspect_ratio = 1.0
                    alpha_values.append(aspect_ratio)

            phi = np.array(normalized_volumes)
            lambda_i = np.array(lambda_values)
            alpha_i = np.array(alpha_values)

            if not np.isclose(np.sum(phi), 1.0, atol=0.001):
                phi = phi / np.sum(phi)

        try:
            effective_tc = model_func(phi=phi, lambda_i=lambda_i, alpha_i=alpha_i)
            phase_results[phase] = {
                'tc': effective_tc,
                'ar': np.average(alpha_i, weights=phi)
            }
        except Exception as e:
            raise ValueError(f"Error processing phase {phase}: {str(e)}")

    if not mix_df.empty:
        mix_order = determine_mix_hierarchy(mix_df)

        for mix_name in mix_order:
            mix_components_df = mix_df[mix_df['Phase'] == mix_name]

            mix_component_props = []
            for _, row in mix_components_df.iterrows():
                component_name = row['Component']

                tc, ar = resolve_component(component_name, phase_results, non_mix_df, phase_volumes, phase_aspect_ratios, row)

                if not pd.isna(row['Aspect_Ratio']):
                    ar = row['Aspect_Ratio']

                mix_component_props.append({
                    'tc': tc,
                    'ar': ar,
                    'vol': row['Volume']
                })

            phi = np.array([comp['vol'] for comp in mix_component_props])
            lambda_i = np.array([comp['tc'] for comp in mix_component_props])
            alpha_i = np.array([comp['ar'] for comp in mix_component_props])

            if phi.sum() > 0:
                phi = phi / phi.sum()

            mix_model = mix_components_df['Model_Type'].iloc[0]
            model_func = get_model_function(mix_model)


            effective_tc = model_func(phi=phi, lambda_i=lambda_i, alpha_i=alpha_i)

            phase_results[mix_name] = {
                'tc': effective_tc,
                'ar': np.average(alpha_i, weights=phi)
            }

    if not mix_df.empty:
        final_mix = determine_mix_hierarchy(mix_df)[-1]
        effective_tc = phase_results[final_mix]['tc']
    else:
        final_model = get_model_function(model_config['final'])
        effective_tc = 1.0  # Default

    return {
        'Effective_TC': float(effective_tc),
        'Components': len(df),
        'Phase_TCs': phase_results
    }


def generate_output(base_df, base_results, range_results, output_file):
    component_names = [c for c in base_df[base_df['Phase'] != 'Mix']['Component'].unique() if c != '-']

    mix_components = base_df[base_df['Phase'] == 'Mix']['Component'].tolist()

    headers = ["Run", "Effective_TC", "Components"]

    if len(base_df['Level'].unique()) > 1 or mix_components:
        for phase in base_results.get('Phase_TCs', {}):
            headers.append(f"TC_{phase}")

    for comp in mix_components:
        headers.append(f"MixVol_{comp}")
        headers.append(f"MixAR_{comp}")

    for comp in component_names:
        headers.extend([
            f"TC_{comp}",
            f"AR_{comp}",
            f"Vol_{comp}"
        ])

    with open(output_file, 'w') as f:
        f.write("\t".join(headers) + "\n")

        base_row = [
            "Base",
            f"{base_results['Effective_TC']:.6f}",
            str(base_results['Components']),
        ]

        if len(base_df['Level'].unique()) > 1 or mix_components:
            for phase in base_results.get('Phase_TCs', {}):
                tc_value = base_results['Phase_TCs'][phase]['tc'] if isinstance(base_results['Phase_TCs'][phase], dict) else base_results['Phase_TCs'][phase]
                base_row.append(f"{tc_value:.6f}")

        for comp in mix_components:
            mix_row = base_df[(base_df['Phase'] == 'Mix') & (base_df['Component'] == comp)].iloc[0]
            base_row.append(f"{mix_row['Volume']:.6f}")
            base_row.append(f"{mix_row['Aspect_Ratio']:.6f}")

        for comp in component_names:
            comp_rows = base_df[base_df['Component'] == comp]
            if len(comp_rows) > 0:
                comp_row = comp_rows.iloc[0]
                base_row.extend([
                    f"{comp_row['Thermal_Conductivity']:.6f}",
                    f"{comp_row['Aspect_Ratio']:.6f}",
                    f"{comp_row['Volume']:.6f}"
                ])
            else:
                base_row.extend(["", "", ""])

        f.write("\t".join(base_row) + "\n")

        for run_id, result in enumerate(range_results, start=1):
            df_current = result.get('df', base_df)

            row = [
                str(run_id),
                f"{result['Effective_TC']:.6f}",
                str(result.get('Components', base_results['Components'])),
            ]

            if len(base_df['Level'].unique()) > 1 or mix_components:
                for phase in result.get('Phase_TCs', {}):
                    tc_value = result['Phase_TCs'][phase]['tc'] if isinstance(result['Phase_TCs'][phase], dict) else result['Phase_TCs'][phase]
                    row.append(f"{tc_value:.6f}")

            for comp in mix_components:
                mix_row = df_current[(df_current['Phase'] == 'Mix') & (df_current['Component'] == comp)]
                if len(mix_row) > 0:
                    row.append(f"{mix_row.iloc[0]['Volume']:.6f}")
                    row.append(f"{mix_row.iloc[0]['Aspect_Ratio']:.6f}")
                else:
                    row.extend(["", ""])

            for comp in component_names:
                comp_rows = df_current[df_current['Component'] == comp]
                if len(comp_rows) > 0:
                    comp_row = comp_rows.iloc[0]
                    row.extend([
                        f"{comp_row['Thermal_Conductivity']:.6f}",
                        f"{comp_row['Aspect_Ratio']:.6f}",
                        f"{comp_row['Volume']:.6f}"
                    ])
                else:
                    row.extend(["", "", ""])

            f.write("\t".join(row) + "\n")


def main(input_file: str = "input.txt", output_file: str = "results_test.txt"):
    try:
        global processor
        processor = RockPropertiesProcessor(input_file)
        logger.info("Input file loaded successfully: %s", input_file)

        base_results = calculate_effective_tc(processor.df, processor.phase_volumes,
                                            processor.phase_aspect_ratios, processor.model_config)
        logger.info("Base calculation completed: Effective_TC=%.6f", base_results['Effective_TC'])

        range_results = []
        if processor.range_parameters:
            logger.info("Processing range parameters: %s", processor.range_parameters.keys())
            for key, values in processor.range_parameters.items():
                param_name = key[0]
                if param_name in ['Phases_Aspect_Ratio', 'Phases_Volume']:
                    phase = key[1]
                    logger.info("Processing parameter %s for %s", param_name, phase)
                    base_df = processor.df.copy()
                    base_phase_volumes = processor.phase_volumes.copy()
                    base_phase_aspect_ratios = processor.phase_aspect_ratios.copy()
                    for i, value in enumerate(values, 1):
                        modified_df = base_df.copy()
                        modified_phase_volumes = base_phase_volumes.copy()
                        modified_phase_aspect_ratios = base_phase_aspect_ratios.copy()
                        if param_name == 'Phases_Volume':
                            modified_phase_volumes = processor._normalize_phase_volumes(
                                base_phase_volumes, phase, value)
                        elif param_name == 'Phases_Aspect_Ratio':
                            modified_phase_aspect_ratios[phase] = value
                        result = calculate_effective_tc(modified_df, modified_phase_volumes,
                                                      modified_phase_aspect_ratios, processor.model_config)
                        logger.info("Run %d completed for %s=%s: Effective_TC=%.6f",
                                  i, param_name, value, result['Effective_TC'])
                        result['df'] = modified_df
                        result['phase_volumes'] = modified_phase_volumes
                        result['phase_aspect_ratios'] = modified_phase_aspect_ratios
                        range_results.append(result)
                else:
                    phase, component = key[1], key[2]
                    logger.info("Processing parameter %s for %s, %s", param_name, phase, component)
                    base_df = processor.df.copy()
                    base_phase_volumes = processor.phase_volumes.copy()
                    base_phase_aspect_ratios = processor.phase_aspect_ratios.copy()

                    mask = (base_df['Phase'] == phase) & (base_df['Component'] == component)
                    if not mask.any():
                        similar_components = base_df[base_df['Phase'] == phase]['Component'].tolist()
                        logger.warning("Component %s not found in phase %s. Available components: %s",
                                      component, phase, similar_components)

                        if 'Mix' in phase and 'Mix1' in component:
                            corrected_component = 'Mix1'
                            if corrected_component in similar_components:
                                logger.info("Using corrected component name: %s", corrected_component)
                                component = corrected_component
                                mask = (base_df['Phase'] == phase) & (base_df['Component'] == component)
                            else:
                                raise ValueError(f"Component {component} not found in phase {phase}. Available components: {similar_components}")
                        else:
                            raise ValueError(f"Component {component} not found in phase {phase}. Available components: {similar_components}")

                    for i, value in enumerate(values, 1):
                        modified_df = base_df.copy()
                        modified_phase_volumes = base_phase_volumes.copy()
                        modified_phase_aspect_ratios = base_phase_aspect_ratios.copy()

                        if param_name in ['Thermal_Conductivity', 'Aspect_Ratio']:
                            mask = (modified_df['Phase'] == phase) & (modified_df['Component'] == component)
                            modified_df.loc[mask, param_name] = value

                        elif param_name == 'Volume':
                            if phase.startswith('Mix'):
                                mix_mask = (modified_df['Phase'] == phase) & (modified_df['Component'] == component)
                                if not mix_mask.any():
                                    raise ValueError(f"Mix component {component} not found in phase {phase}")

                                modified_df.loc[mix_mask, 'Volume'] = value
                                modified_phase_volumes[component] = value

                                total_mix_volume = modified_df[modified_df['Phase'] == phase]['Volume'].sum()
                                if not np.isclose(total_mix_volume, 1.0, atol=0.001):
                                    other_components_mask = (modified_df['Phase'] == phase) & (~mix_mask)
                                    if other_components_mask.any():
                                        total_other_volume = modified_df.loc[other_components_mask, 'Volume'].sum()
                                        if total_other_volume > 0:
                                            scaling = (1.0 - value) / total_other_volume
                                            modified_df.loc[other_components_mask, 'Volume'] *= scaling
                                            for comp_name in modified_df.loc[other_components_mask, 'Component']:
                                                modified_phase_volumes[comp_name] *= scaling
                            else:
                                mask = (modified_df['Phase'] == phase) & (modified_df['Component'] == component)
                                if not mask.any():
                                    raise ValueError(f"Component {component} not found in phase {phase}")

                                modified_df.loc[mask, 'Volume'] = value

                                phase_mask = modified_df['Phase'] == phase
                                other_components_mask = phase_mask & (~mask)

                                if other_components_mask.any():
                                    total_other_volume = modified_df.loc[other_components_mask, 'Volume'].sum()
                                    if total_other_volume > 0:
                                        phase_total = modified_df.loc[phase_mask, 'Volume'].sum()
                                        scaling = (phase_total - value) / total_other_volume
                                        modified_df.loc[other_components_mask, 'Volume'] *= scaling

                        result = calculate_effective_tc(modified_df, modified_phase_volumes,
                                                      modified_phase_aspect_ratios, processor.model_config)
                        logger.info("Run %d completed for %s=%s (Phase: %s, Component: %s): Effective_TC=%.6f",
                                  i, param_name, value, phase, component, result['Effective_TC'])

                        result['df'] = modified_df
                        result['phase_volumes'] = modified_phase_volumes
                        result['phase_aspect_ratios'] = modified_phase_aspect_ratios
                        range_results.append(result)

        generate_output(processor.df, base_results, range_results, output_file)
        print(f"Results saved to {output_file}")


    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":

  if len(sys.argv) < 2:
      print("Error: Input file name is required.")
      sys.exit(1)
  elif len(sys.argv) == 2:
      input_filename = sys.argv[1]
      base_name = os.path.splitext(input_filename)[0]
      output_filename = f"{base_name}_results.txt"
  else:
      input_filename = sys.argv[1]
      output_filename = sys.argv[2]

  main(input_file=input_filename, output_file=output_filename)